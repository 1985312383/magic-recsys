### 第一章：核心概念（01_Concepts）
**本章目标**：让学生像产品经理一样理解业务逻辑，像架构师一样理解系统评价标准。

*   **01_Definition：推荐系统的本质与进化**
    *   **生活实例**：从“刷抖音”到“逛淘宝”，推荐系统如何在你没开口时就“读懂”你。
    *   **本质逻辑**：推荐系统 = 信息过载时的自动化过滤器。
    *   **关键区别**：对比“信息检索（搜索）”的主动性与“推荐系统”的被动感知。
    *   **进化简史**：从人工编辑 -> 规则统计 -> 协同过滤 -> 深度学习 -> 生成式推荐。

*   **02_Scenarios：工业界核心业务场景**
    *   **电商场景**：以亚马逊/淘宝为例，核心是转化率（CVR）与 GMV。
    *   **内容场景**：以抖音/快手/YouTube 为例，核心是停留时长与留存率。
    *   **新闻场景（对接MIND）**：以今日头条为例，核心是点击率（CTR）与内容时效性。
    *   **社交场景**：以朋友圈/微博为例，核心是互动率（点赞/评论/转发）。

*   **03_Evaluation：线上与离线评测体系**
    *   **离线指标**：解释分类指标（准确率/召回率/F1）、排序指标（NDCG/Hit Rate）和回归指标（RMSE）。
    *   **在线指标（北极星）**：点击率（CTR）、转化率（CVR）、留存（Retention）。
    *   **“魔法”指标**：多样性（Diversity）、覆盖率（Coverage）、惊喜度（Serendipity）。
    *   **A/B Test 概念**：为什么线上数据才是最终的裁判？

*   **04_Search_Ads_Basics：[选修] 搜广推的关联与差异**
    *   **核心对比**：
        *   搜索：User + Query -> 相关性（满足即时意图）。
        *   推荐：User + Context -> 兴趣度（挖掘潜在意图）。
        *   广告：User + Context + Ad -> 商业收益（eCPM = CTR * Bid）。
    *   **收敛趋势**：底层技术栈的高度重合（双塔召回、精排模型）。

---

### 第二章：模型基石（02_Classics）
**本章目标**：让学生通过纯手写代码（Numpy/Pandas），彻底理解经典推荐算法的数学灵魂。

*   **01_MIND_Dataset：微软新闻数据集 (MIND) 解析**
    *   **数据下载与采样**：如何获取 MIND-small 数据集。
    *   **字段解密**：
        *   `Behaviors.tsv`：用户历史点击序列、当前曝光列表（重点讲解正负样本）。
        *   `News.tsv`：新闻标题、类别、子类别、实体信息（为后续 NLP 处理埋下伏笔）。
    *   **数据清洗练习**：用 Pandas 统计新闻类别分布，分析用户活跃度。

*   **02_CF_Numpy：协同过滤：纯 Numpy 实现**
    *   **User-CF 逻辑**：找到“臭味相投”的人，推荐他们喜欢的东西（纯 Numpy 计算余弦相似度矩阵）。
    *   **Item-CF 逻辑**：因为你喜欢 A，所以给你推荐和 A 相似的 B（手动构建物品相似度矩阵）。
    *   **代码挑战**：不使用 Sklearn，手写最原始的相似度预测函数。
    *   **优缺点复盘**：数据稀疏性问题、冷启动问题。

*   **03_Matrix_Factorization：矩阵分解：隐向量建模**
    *   **从计算到编码**：为什么说 MF 是 Embedding（嵌入）思想的鼻祖？
    *   **数学推导**：将“用户-物品评分矩阵”拆解为两个低秩矩阵 $P$ 和 $Q$。
    *   **SVD 概念简述**：理解如何用隐向量代表一个人的兴趣特征。
    *   **实践**：用 Numpy 手写一个简易的 ALS（交替最小二乘法）或梯度下降逻辑，补全缺失分。

*   **04_Logistic_Regression：线性模型：CTR 预估起步**
    *   **推荐作为分类问题**：为什么预测用户“点不点”比预测“打几分”更重要？
    *   **特征拼接**：将用户 ID、物品类别、上下文信息拼接成一个 Feature Vector。
    *   **Sigmoid 的魔法**：如何把线性输出转化为 0 到 1 之间的点击概率。
    *   **LR 的局限**：引出后续第三章“深度交叉特征”的必要性（FM 与 DeepFM 的动机）。

### 第三章：深度进阶（03_Advanced）
**本章目标**：实现从线性模型到神经网络模型的跨越，掌握向量化检索（召回）的核心技术。

*   **01_Feature_Embedding：特征工程：Embedding 艺术**
    *   **离散 vs 连续**：One-hot 的困境与词嵌入（Embedding）的降维打击。
    *   **处理 MIND 文本**：利用预训练模型（如 BERT）提取新闻标题特征。
    *   **权重共享**：理解 Embedding 层在神经网络中本质上是一个“可学习的查找表”。
    *   **实战**：使用 PyTorch 实现一个简单的 Embedding 层。

*   **02_DeepFM_Scratch：手搓 DeepFM：底层算子实现**
    *   **模型拆解**：FM 部分（提取低阶交叉特征）与 DNN 部分（提取高阶非线性特征）。
    *   **算子实现**：手写 FM 的二阶交叉项优化公式（和平方减方和）。
    *   **联合训练**：双路架构的梯度同步与权重更新逻辑。
    *   **原理验证**：通过 MIND 小样本验证手写模型的收敛过程。

*   **03_Torch_RecHub_API：Torch-RecHub：工业框架应用**
    *   **降维打击**：对比“手搓”与“封装”，展示工业级框架如何处理百万级特征。
    *   **特征定义**：使用 `DenseFeature` 和 `SparseFeature` 进行特征工程配置。
    *   **一键切换**：演示如何通过一行代码从 DeepFM 切换到 DIN 或 DCN。
    *   **效率对比**：展示框架在并行计算和模型部署上的优势。

*   **04_Vector_Recall_Annoy：向量召回：双塔模型与 Annoy**
    *   **召回逻辑**：为什么排序模型（精排）不能直接处理千万级数据？
    *   **双塔架构（DSSM）**：User 塔与 Item 塔的语义对齐。
    *   **近邻检索**：引入 **Annoy** 库，理解索引构建（Build）与快速检索（Query）。
    *   **实战**：导出 User 向量，在 Annoy 库中检索最匹配的新闻。

*   **05_Ad_Strategies_MTL：[选修] 广告：多目标学习与竞价**
    *   **多目标需求**：不仅要点击（CTR），还要转化（CVR）。
    *   **典型模型**：MMoE（多门控专家混合模型）原理简述。
    *   **竞价魔法**：理解 eCPM（点击率 × 出价）及其在广告排序中的权重。

*   **06_Search_Query_Engine：[选修] 搜索：Query 理解与检索**
    *   **即时意图**：Query 编码与历史兴趣的融合。
    *   **语义匹配**：文本语义召回与关键词召回的权衡。

---

### 第四章：工程闭环（04_Engineering）
**本章目标**：搭建 **News-Flow** 系统，复现工业界真实的“自迭代”闭环。

*   **01_Flow_Architecture：自迭代系统：架构蓝图设计**
    *   **全景视图**：从 App 触发请求到排序结果返回的“数据旅行图”。
    *   **模块解耦**：为什么需要将召回、精排、特征服务拆分为独立模块？
    *   **自迭代设计**：日志如何回流到训练集，驱动模型“天天向上”。

*   **02_FastAPI_Endpoint：服务层：基于 FastAPI 的响应**
    *   **高性能网关**：使用 FastAPI 搭建推荐系统对外的 HTTP 接口。
    *   **异步请求处理**：在高并发场景下如何保证推荐结果的秒级返回。
    *   **数据契约**：定义输入（用户 ID、上下文）与输出（推荐列表、分数）的 JSON 规范。

*   **03_Thrift_RPC：通信层：Thrift 实现解耦调用**
    *   **RPC vs HTTP**：为什么大厂内部服务间通信更偏爱 RPC？
    *   **接口定义（IDL）**：编写 `.thrift` 文件，定义召回与排序服务的契约。
    *   **跨语言可能**：演示如何通过 Thrift 让不同技术栈的服务顺畅沟通。

*   **04_Redis_Storage：存储层：Redis 在线特征查询**
    *   **读多写少**：将预计算好的 User/Item Embedding 和特征画像存入 Redis。
    *   **实时查找**：召回完成后，快速通过 Redis 补全特征，喂给排序模型。
    *   **缓存策略**：热点数据与冷启动用户的缓存处理。

*   **05_Loop_Iteration：闭环层：落日志与全自动迭代**
    *   **落日志（Exposure Log）**：在推荐返回的同时，记录这一刻的特征快照。
    *   **样本构建**：结合曝光日志与用户点击（Click Log）自动生成新的训练样本。
    *   **触发训练**：模拟模型自动更新的逻辑，让 News-Flow 系统实现真正的生命力。

---

### 第五章：前沿实战（05_Frontiers）
**本章目标**：探索 2024-2026 年最前沿的生成式推荐趋势。

*   **01_Generative_Rec_LLM：LLM 时代的生成式推荐复现**
    *   **范式转移**：从“判别式（打分）”到“生成式（直接生成新闻标题或 ID）”。
    *   **Prompt Engineering**：如何把用户的历史点击行为喂给大模型做个性化摘要。
    *   **复现实战**：利用微调后的轻量级大模型（如 LLaMA-3）对 MIND 数据集进行直接推荐，并与传统 DeepFM 对比。
    *   **局限与思考**：生成式推荐在推理成本与实时性上的挑战。

---

### 第六章：专题深潜（06_Special_Topics）

*   **01_Advanced_AB_Test：A/B 测试的工业级玩法**
    *   **正文外扩展**：不只是简单的 50/50 分流。
    *   **层叠实验框架（Layering）**：如何在同一批用户身上同时跑 10 个不互相干扰的实验（流量正交）。
    *   **Interleaving（交织评估）**：Netflix 也在用的评估神技，为什么它比 A/B Test 快 100 倍？
    *   **统计学陷阱**：辛普森悖论、样本污染、如何科学地计算置信区间。

*   **02_Cold_Start_Mastery：冷启动的进阶破局**
    *   **正文外扩展**：除了推热门和推分类。
    *   **Look-alike 逻辑**：新用户进来，如何快速通过其有限的画像在老用户中找到“双胞胎”。
    *   **Bandit 算法（E&E）**：汤普森采样 (Thompson Sampling) 和 UCB 算法，如何科学地“试错”。
    *   **零样本推荐**：利用 LLM 语义 Embedding 赋予新物品初始“灵魂”。

*   **03_Reranking_Strategies：重排与多样性魔术**
    *   **打分不是终点**：为什么精排分数最高的 10 个物品直接推给用户是灾难？
    *   **多样性算法**：MMR（最大边界相关法）和 DPP（行列式点过程），如何平衡精准度和新鲜感。
    *   **业务打散策略**：同一个作者的内容不能连续出现、类目打散、样式打散。

*   **04_Realtime_Features：实时特征工程的细节**
    *   **滑动窗口**：如何计算用户过去 1 分钟、5 分钟、1 小时的实时行为。
    *   **行为序列建模**：用户的最后 5 次点击序列如何瞬间改变下一次的召回结果。
    *   **特征穿越防控**：在工程上如何绝对避免“拿着答案找题目”的低级错误。

*   **05_Model_Calibration：预估分数校准**
    *   **为什么要校准**：模型给出的 0.9 分真的代表 90% 的点击率吗？
    *   **校准方法**：Platt Scaling、Isotonic Regression，让模型的分数具备真实的物理含义（对广告业务至关重要）。


---

### 编写建议：
1.  **第一章**要多配图，尤其是业务场景和 A/B Test 的示意图，增加直观感。
2.  **第二章**的每一个小节最后，都要附带一个 **"Show Me The Code"** 环节。
3.  **衔接设计**：在 02.04（LR）的末尾，一定要抛出一个悬念：“如果特征之间有复杂的非线性关系，LR 这种一阶模型搞不定怎么办？”，从而自然过渡到第三章的深度学习模型。
4.  **第三章（模型篇）**：
    *   **代码对比**：在 03.02 和 03.03 章节，采用“左右分栏”或“前后对比”的方式展示手动实现与 RecHub 实现的差异，通过“代码量对比”突出工具价值。
5.  **第四章（工程篇）**：
    *   **架构先行**：每一个小节开头都复现一次整体架构图，并高亮当前章节所在的模块，防止读者在复杂的 RPC 调用中迷失方向。
    *   **Docker 一键拉起**：建议在最后提供一个 `docker-compose` 脚本，让学生能一键启动 Redis、Thrift 和 FastAPI，降低环境配置难度。
6.  **第五章（前沿篇）**：
    *   **保持开放**：生成式推荐仍在快速进化，这一章应多引入前沿论文链接，鼓励读者探索。